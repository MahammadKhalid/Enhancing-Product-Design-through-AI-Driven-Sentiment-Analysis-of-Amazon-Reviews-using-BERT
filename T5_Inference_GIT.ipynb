{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-fOJLwq6Mn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch\n",
        "!pip install -U -q accelerate transformers\n",
        "!pip install -q sentencepiece\n",
        "!pip install --upgrade -q simplet5\n",
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "1FQ1NvJ8rCUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from simplet5 import SimpleT5"
      ],
      "metadata": {
        "id": "jUsiJEvvrKXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation file path\n",
        "VALIDATION_FILE_PATH = '/content/drive/MyDrive/ASPECT ANALYSIS ALL/post split 80 20 ratio train test data/testing_data_20.csv'"
      ],
      "metadata": {
        "id": "65OKqnO6rO7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the excel file into a pandas dataframe\n",
        "validation_data = pd.read_csv(VALIDATION_FILE_PATH)"
      ],
      "metadata": {
        "id": "m6tg9P37rO-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the duplicate reviews if any\n",
        "validation_data = validation_data.drop_duplicates(subset=['Review'])\n",
        "# deleting the rows with null values if any\n",
        "validation_data = validation_data.dropna()"
      ],
      "metadata": {
        "id": "HHDzmlETrPCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the labels\n",
        "label_replacements = {\n",
        "    'Ease of Use': 'Usability',\n",
        "    'Ease of Reprocessing': 'Reprocessability',\n",
        "    'Ease of Storage': 'Storability',\n",
        "}\n",
        "# reverseing the dictionary above\n",
        "label_replacements_reverse = {\n",
        "    'Usability': 'Ease of Use',\n",
        "    'Reprocessability': 'Ease of Reprocessing',\n",
        "    'Storability': 'Ease of Storage',\n",
        "}"
      ],
      "metadata": {
        "id": "sQEoqcp5rPFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of original labels\n",
        "original_labels = [\n",
        "    'Adaptability', 'Durability', 'Ease of Use', 'Ergonomics',\n",
        "    'Interference', 'Performance', 'Use Efficiency', 'Aesthetics',\n",
        "    'Ease of Reprocessing', 'Ease of Storage', 'Price', 'Safety'\n",
        "]\n",
        "\n",
        "modified_labels = [\n",
        "    'Adaptability', 'Durability', 'Usability', 'Ergonomics',\n",
        "    'Interference', 'Performance', 'Use Efficiency', 'Aesthetics',\n",
        "    'Reprocessability', 'Storability', 'Price', 'Safety'\n",
        "]\n"
      ],
      "metadata": {
        "id": "dVYAyDjprcRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SimpleT5 requires that we specify the use case before each review\n",
        "testing_data['source_text'] = \"predict Aspect: \"+ testing_data['source_text']"
      ],
      "metadata": {
        "id": "B1OLHi5QrcUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleT5()"
      ],
      "metadata": {
        "id": "-jiU-R1urcXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load trained T5 model\n",
        "model.load_model(\"t5\",\"/content/drive/MyDrive/ASPECT ANALYSIS ALL/T5_MODEL_FILES/simplet5-smallmodel\", use_gpu=True)\n",
        "# to load the base model\n",
        "# model.load_model(\"t5\",\"/content/drive/MyDrive/ASPECT ANALYSIS ALL/T5_MODEL_FILES/simplet5-basemodel\", use_gpu=True)"
      ],
      "metadata": {
        "id": "cHeaPtMDrmGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for rev in testing_data.source_text.values:\n",
        "    pred = model.predict(rev)[0]\n",
        "    predictions.append(pred)"
      ],
      "metadata": {
        "id": "twZosvSvrmJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing sentence transformers, to map the new labels to original labels based on cosine similarity\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "y-7qd_CermOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the embedding model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "D5tVt3XrscdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating embeddings for the original labels\n",
        "original_labels_embeddings = embedder.encode(original_labels, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "4Na0t3oxscgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using sentence transformer to map new T5 generated labels to original labels using cosine similarity\n",
        "mapped_predictions_new_labels = []\n",
        "for predicted_value in predictions:\n",
        "    if predicted_value in modified_labels:\n",
        "        mapped_predictions_new_labels.append(predicted_value)\n",
        "    else:\n",
        "      pred_embedding = embedder.encode(predicted_value, convert_to_tensor=True)\n",
        "      cos_scores = util.cos_sim(pred_embedding, original_labels_embeddings)[0]\n",
        "      top_result = torch.topk(cos_scores, k=1)\n",
        "      for score, idx in zip(top_result[0], top_result[1]):\n",
        "          mapped_predictions_new_labels.append(original_labels[idx])"
      ],
      "metadata": {
        "id": "6K5jVm2QshDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(labels, preds):\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
        "    precision = precision_score(y_true=labels, y_pred=preds, average='weighted')\n",
        "    recall = recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
        "    f1score = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
        "    return {\"accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1_score\": f1score}"
      ],
      "metadata": {
        "id": "pSAwJv6dszVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_mapped_to_original = [label_replacements_reverse[item] if item in label_replacements_reverse else item for item in mapped_predictions_new_labels]"
      ],
      "metadata": {
        "id": "0ZM-U1y6scjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrics(testing_data.Aspect.values, predictions_mapped_to_original)"
      ],
      "metadata": {
        "id": "uRf8j9zvs0WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing_data.Aspect.values, predictions_mapped_to_original))"
      ],
      "metadata": {
        "id": "yrNZbwTps0ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlIG-MN5s0cL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}